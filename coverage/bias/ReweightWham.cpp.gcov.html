<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - plumed test coverage - bias/ReweightWham.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">bias</a> - ReweightWham.cpp<span style="font-size: 80%;"> (source / <a href="ReweightWham.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">plumed test coverage</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">45</td>
            <td class="headerCovTableEntry">49</td>
            <td class="headerCovTableEntryHi">91.8 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2024-10-18 14:29:08</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">9</td>
            <td class="headerCovTableEntry">11</td>
            <td class="headerCovTableEntryMed">81.8 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</a>
<a name="2"><span class="lineNum">       2 </span>            :    Copyright (c) 2017-2023 The plumed team</a>
<a name="3"><span class="lineNum">       3 </span>            :    (see the PEOPLE file at the root of the distribution for a list of names)</a>
<a name="4"><span class="lineNum">       4 </span>            : </a>
<a name="5"><span class="lineNum">       5 </span>            :    See http://www.plumed.org for more information.</a>
<a name="6"><span class="lineNum">       6 </span>            : </a>
<a name="7"><span class="lineNum">       7 </span>            :    This file is part of plumed, version 2.</a>
<a name="8"><span class="lineNum">       8 </span>            : </a>
<a name="9"><span class="lineNum">       9 </span>            :    plumed is free software: you can redistribute it and/or modify</a>
<a name="10"><span class="lineNum">      10 </span>            :    it under the terms of the GNU Lesser General Public License as published by</a>
<a name="11"><span class="lineNum">      11 </span>            :    the Free Software Foundation, either version 3 of the License, or</a>
<a name="12"><span class="lineNum">      12 </span>            :    (at your option) any later version.</a>
<a name="13"><span class="lineNum">      13 </span>            : </a>
<a name="14"><span class="lineNum">      14 </span>            :    plumed is distributed in the hope that it will be useful,</a>
<a name="15"><span class="lineNum">      15 </span>            :    but WITHOUT ANY WARRANTY; without even the implied warranty of</a>
<a name="16"><span class="lineNum">      16 </span>            :    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</a>
<a name="17"><span class="lineNum">      17 </span>            :    GNU Lesser General Public License for more details.</a>
<a name="18"><span class="lineNum">      18 </span>            : </a>
<a name="19"><span class="lineNum">      19 </span>            :    You should have received a copy of the GNU Lesser General Public License</a>
<a name="20"><span class="lineNum">      20 </span>            :    along with plumed.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</a>
<a name="21"><span class="lineNum">      21 </span>            : +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ */</a>
<a name="22"><span class="lineNum">      22 </span>            : #include &quot;ReweightBase.h&quot;</a>
<a name="23"><span class="lineNum">      23 </span>            : #include &quot;core/ActionRegister.h&quot;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &quot;tools/Communicator.h&quot;</a>
<a name="25"><span class="lineNum">      25 </span>            : </a>
<a name="26"><span class="lineNum">      26 </span>            : //+PLUMEDOC REWEIGHTING REWEIGHT_WHAM</a>
<a name="27"><span class="lineNum">      27 </span>            : /*</a>
<a name="28"><span class="lineNum">      28 </span>            : Calculate the weights for configurations using the weighted histogram analysis method.</a>
<a name="29"><span class="lineNum">      29 </span>            : </a>
<a name="30"><span class="lineNum">      30 </span>            : Suppose that you have run multiple \f$N\f$ trajectories each of which was computed by integrating a different biased Hamiltonian. We can calculate the probability of observing</a>
<a name="31"><span class="lineNum">      31 </span>            : the set of configurations during the \f$N\f$ trajectories that we ran using the product of multinomial distributions shown below:</a>
<a name="32"><span class="lineNum">      32 </span>            : \f[</a>
<a name="33"><span class="lineNum">      33 </span>            : P( \vec{T} ) \propto \prod_{j=1}^M \prod_{k=1}^N (c_k w_{kj} p_j)^{t_{kj}}</a>
<a name="34"><span class="lineNum">      34 </span>            : \label{eqn:wham1}</a>
<a name="35"><span class="lineNum">      35 </span>            : \f]</a>
<a name="36"><span class="lineNum">      36 </span>            : In this expression the second product runs over the biases that were used when calculating the \f$N\f$ trajectories.  The first product then runs over the</a>
<a name="37"><span class="lineNum">      37 </span>            : \f$M\f$ bins in our histogram.  The \f$p_j\f$ variable that is inside this product is the quantity we wish to extract; namely, the unbiased probability of</a>
<a name="38"><span class="lineNum">      38 </span>            : having a set of CV values that lie within the range for the \f$j\f$th bin.</a>
<a name="39"><span class="lineNum">      39 </span>            : </a>
<a name="40"><span class="lineNum">      40 </span>            : The quantity that we can easily extract from our simulations, \f$t_{kj}\f$, however, measures the number of frames from trajectory \f$k\f$ that are inside the \f$j\f$th bin.</a>
<a name="41"><span class="lineNum">      41 </span>            : To interpret this quantity we must consider the bias that acts on each of the replicas so the \f$w_{kj}\f$ term is introduced.  This quantity is calculated as:</a>
<a name="42"><span class="lineNum">      42 </span>            : \f[</a>
<a name="43"><span class="lineNum">      43 </span>            : w_{kj} =</a>
<a name="44"><span class="lineNum">      44 </span>            : \f]</a>
<a name="45"><span class="lineNum">      45 </span>            : and is essentially the factor that we have to multiply the unbiased probability of being in the bin by in order to get the probability that we would be inside this same bin in</a>
<a name="46"><span class="lineNum">      46 </span>            : the \f$k\f$th of our biased simulations.  Obviously, these \f$w_{kj}\f$ values depend on the value that the CVs take and also on the particular trajectory that we are investigating</a>
<a name="47"><span class="lineNum">      47 </span>            : all of which, remember, have different simulation biases.  Finally, \f$c_k\f$ is a free parameter that ensures that, for each \f$k\f$, the biased probability is normalized.</a>
<a name="48"><span class="lineNum">      48 </span>            : </a>
<a name="49"><span class="lineNum">      49 </span>            : We can use the equation for the probability that was given above to find a set of values for \f$p_j\f$ that maximizes the likelihood of observing the trajectory.</a>
<a name="50"><span class="lineNum">      50 </span>            : This constrained optimization must be performed using a set of Lagrange multipliers, \f$\lambda_k\f$, that ensure that each of the biased probability distributions</a>
<a name="51"><span class="lineNum">      51 </span>            : are normalized, that is \f$\sum_j c_kw_{kj}p_j=1\f$.  Furthermore, as the problem is made easier if the quantity in the equation above is replaced by its logarithm</a>
<a name="52"><span class="lineNum">      52 </span>            : we actually chose to minimize</a>
<a name="53"><span class="lineNum">      53 </span>            : \f[</a>
<a name="54"><span class="lineNum">      54 </span>            : \mathcal{L}= \sum_{j=1}^M \sum_{k=1}^N t_{kj} \ln c_k  w_{kj} p_j + \sum_k\lambda_k \left( \sum_{j=1}^N c_k w_{kj} p_j - 1 \right)</a>
<a name="55"><span class="lineNum">      55 </span>            : \f]</a>
<a name="56"><span class="lineNum">      56 </span>            : After some manipulations the following (WHAM) equations emerge:</a>
<a name="57"><span class="lineNum">      57 </span>            : \f[</a>
<a name="58"><span class="lineNum">      58 </span>            : \begin{aligned}</a>
<a name="59"><span class="lineNum">      59 </span>            : p_j &amp; \propto \frac{\sum_{k=1}^N t_{kj}}{\sum_k c_k w_{kj}} \\</a>
<a name="60"><span class="lineNum">      60 </span>            : c_k &amp; =\frac{1}{\sum_{j=1}^M w_{kj} p_j}</a>
<a name="61"><span class="lineNum">      61 </span>            : \end{aligned}</a>
<a name="62"><span class="lineNum">      62 </span>            : \f]</a>
<a name="63"><span class="lineNum">      63 </span>            : which can be solved by computing the \f$p_j\f$ values using the first of the two equations above with an initial guess for the \f$c_k\f$ values and by then refining</a>
<a name="64"><span class="lineNum">      64 </span>            : these \f$p_j\f$ values using the \f$c_k\f$ values that are obtained by inserting the \f$p_j\f$ values obtained into the second of the two equations above.</a>
<a name="65"><span class="lineNum">      65 </span>            : </a>
<a name="66"><span class="lineNum">      66 </span>            : Notice that only \f$\sum_k t_{kj}\f$, which is the total number of configurations from all the replicas that enter the \f$j\f$th bin, enters the WHAM equations above.</a>
<a name="67"><span class="lineNum">      67 </span>            : There is thus no need to record which replica generated each of the frames.  One can thus simply gather the trajectories from all the replicas together at the outset.</a>
<a name="68"><span class="lineNum">      68 </span>            : This observation is important as it is the basis of the binless formulation of WHAM that is implemented within PLUMED.</a>
<a name="69"><span class="lineNum">      69 </span>            : </a>
<a name="70"><span class="lineNum">      70 </span>            : \par Examples</a>
<a name="71"><span class="lineNum">      71 </span>            : </a>
<a name="72"><span class="lineNum">      72 </span>            : */</a>
<a name="73"><span class="lineNum">      73 </span>            : //+ENDPLUMEDOC</a>
<a name="74"><span class="lineNum">      74 </span>            : </a>
<a name="75"><span class="lineNum">      75 </span>            : namespace PLMD {</a>
<a name="76"><span class="lineNum">      76 </span>            : namespace bias {</a>
<a name="77"><span class="lineNum">      77 </span>            : </a>
<a name="78"><span class="lineNum">      78 </span>            : class ReweightWham : public ReweightBase {</a>
<a name="79"><span class="lineNum">      79 </span>            : private:</a>
<a name="80"><span class="lineNum">      80 </span>            :   double thresh;</a>
<a name="81"><span class="lineNum">      81 </span>            :   unsigned nreplicas;</a>
<a name="82"><span class="lineNum">      82 </span>            :   unsigned maxiter;</a>
<a name="83"><span class="lineNum">      83 </span>            :   bool weightsCalculated;</a>
<a name="84"><span class="lineNum">      84 </span>            :   std::vector&lt;double&gt; stored_biases;</a>
<a name="85"><span class="lineNum">      85 </span>            :   std::vector&lt;double&gt; final_weights;</a>
<a name="86"><span class="lineNum">      86 </span>            : public:</a>
<a name="87"><span class="lineNum">      87 </span>            :   static void registerKeywords(Keywords&amp;);</a>
<a name="88"><span class="lineNum">      88 </span>            :   explicit ReweightWham(const ActionOptions&amp;ao);</a>
<a name="89"><span class="lineNum">      89 </span><span class="lineCov">         12 :   bool buildsWeightStore() const override { return true; }</span></a>
<a name="90"><span class="lineNum">      90 </span>            :   void calculateWeights( const unsigned&amp; nframes ) override;</a>
<a name="91"><span class="lineNum">      91 </span>            :   void clearData() override;</a>
<a name="92"><span class="lineNum">      92 </span>            :   double getLogWeight() override;</a>
<a name="93"><span class="lineNum">      93 </span>            :   double getWeight( const unsigned&amp; iweight ) const override;</a>
<a name="94"><span class="lineNum">      94 </span>            : };</a>
<a name="95"><span class="lineNum">      95 </span>            : </a>
<a name="96"><span class="lineNum">      96 </span><span class="lineCov">      12633 : PLUMED_REGISTER_ACTION(ReweightWham,&quot;REWEIGHT_WHAM&quot;)</span></a>
<a name="97"><span class="lineNum">      97 </span>            : </a>
<a name="98"><span class="lineNum">      98 </span><span class="lineCov">         14 : void ReweightWham::registerKeywords(Keywords&amp; keys ) {</span></a>
<a name="99"><span class="lineNum">      99 </span><span class="lineCov">         14 :   ReweightBase::registerKeywords( keys ); keys.remove(&quot;ARG&quot;);</span></a>
<a name="100"><span class="lineNum">     100 </span><span class="lineCov">         28 :   keys.add(&quot;compulsory&quot;,&quot;ARG&quot;,&quot;*.bias&quot;,&quot;the biases that must be taken into account when reweighting&quot;);</span></a>
<a name="101"><span class="lineNum">     101 </span><span class="lineCov">         28 :   keys.add(&quot;compulsory&quot;,&quot;MAXITER&quot;,&quot;1000&quot;,&quot;maximum number of iterations for WHAM algorithm&quot;);</span></a>
<a name="102"><span class="lineNum">     102 </span><span class="lineCov">         28 :   keys.add(&quot;compulsory&quot;,&quot;WHAMTOL&quot;,&quot;1e-10&quot;,&quot;threshold for convergence of WHAM algorithm&quot;);</span></a>
<a name="103"><span class="lineNum">     103 </span><span class="lineCov">         14 : }</span></a>
<a name="104"><span class="lineNum">     104 </span>            : </a>
<a name="105"><span class="lineNum">     105 </span><span class="lineCov">         12 : ReweightWham::ReweightWham(const ActionOptions&amp;ao):</span></a>
<a name="106"><span class="lineNum">     106 </span>            :   Action(ao),</a>
<a name="107"><span class="lineNum">     107 </span>            :   ReweightBase(ao),</a>
<a name="108"><span class="lineNum">     108 </span><span class="lineCov">         12 :   weightsCalculated(false)</span></a>
<a name="109"><span class="lineNum">     109 </span>            : {</a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">         24 :   parse(&quot;MAXITER&quot;,maxiter); parse(&quot;WHAMTOL&quot;,thresh);</span></a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">         12 :   if(comm.Get_rank()==0) nreplicas=multi_sim_comm.Get_size();</span></a>
<a name="112"><span class="lineNum">     112 </span><span class="lineCov">         12 :   comm.Bcast(nreplicas,0);</span></a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">         12 : }</span></a>
<a name="114"><span class="lineNum">     114 </span>            : </a>
<a name="115"><span class="lineNum">     115 </span><span class="lineCov">       4224 : double ReweightWham::getLogWeight() {</span></a>
<a name="116"><span class="lineNum">     116 </span><span class="lineCov">       4224 :   if( getStep()==0 ) return 1.0;  // This is here as first step is ignored in all analyses</span></a>
<a name="117"><span class="lineNum">     117 </span><span class="lineCov">       4212 :   weightsCalculated=false;</span></a>
<a name="118"><span class="lineNum">     118 </span><span class="lineCov">       8424 :   double bias=0.0; for(unsigned i=0; i&lt;getNumberOfArguments(); ++i) bias+=getArgument(i);</span></a>
<a name="119"><span class="lineNum">     119 </span>            : </a>
<a name="120"><span class="lineNum">     120 </span><span class="lineCov">       4212 :   std::vector&lt;double&gt; biases(nreplicas,0.0);</span></a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">       4212 :   if(comm.Get_rank()==0) multi_sim_comm.Allgather(bias,biases);</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineCov">       4212 :   comm.Bcast(biases,0);</span></a>
<a name="123"><span class="lineNum">     123 </span><span class="lineCov">      29484 :   for(unsigned i=0; i&lt;biases.size(); i++) stored_biases.push_back( biases[i] );</span></a>
<a name="124"><span class="lineNum">     124 </span>            :   return 1.0;</a>
<a name="125"><span class="lineNum">     125 </span>            : }</a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span><span class="lineNoCov">          0 : void ReweightWham::clearData() {</span></a>
<a name="128"><span class="lineNum">     128 </span><span class="lineNoCov">          0 :   stored_biases.resize(0);</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineNoCov">          0 : }</span></a>
<a name="130"><span class="lineNum">     130 </span>            : </a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">       2457 : double ReweightWham::getWeight( const unsigned&amp; iweight ) const {</span></a>
<a name="132"><span class="lineNum">     132 </span>            :   plumed_dbg_assert( weightsCalculated &amp;&amp; iweight&lt;final_weights.size() );</a>
<a name="133"><span class="lineNum">     133 </span><span class="lineCov">       2457 :   return final_weights[iweight];</span></a>
<a name="134"><span class="lineNum">     134 </span>            : }</a>
<a name="135"><span class="lineNum">     135 </span>            : </a>
<a name="136"><span class="lineNum">     136 </span><span class="lineCov">          7 : void ReweightWham::calculateWeights( const unsigned&amp; nframes ) {</span></a>
<a name="137"><span class="lineNum">     137 </span><span class="lineCov">          7 :   if( stored_biases.size()!=nreplicas*nframes ) error(&quot;wrong number of weights stored&quot;);</span></a>
<a name="138"><span class="lineNum">     138 </span>            :   // Get the minimum value of the bias</a>
<a name="139"><span class="lineNum">     139 </span><span class="lineCov">          7 :   double minv = *min_element(std::begin(stored_biases), std::end(stored_biases));</span></a>
<a name="140"><span class="lineNum">     140 </span>            :   // Resize final weights array</a>
<a name="141"><span class="lineNum">     141 </span><span class="lineCov">          7 :   plumed_assert( stored_biases.size()%nreplicas==0 );</span></a>
<a name="142"><span class="lineNum">     142 </span><span class="lineCov">          7 :   final_weights.resize( stored_biases.size() / nreplicas, 1.0 );</span></a>
<a name="143"><span class="lineNum">     143 </span>            :   // Offset and exponential of the bias</a>
<a name="144"><span class="lineNum">     144 </span><span class="lineCov">          7 :   std::vector&lt;double&gt; expv( stored_biases.size() );</span></a>
<a name="145"><span class="lineNum">     145 </span><span class="lineCov">      14749 :   for(unsigned i=0; i&lt;expv.size(); ++i) expv[i] = std::exp( (-stored_biases[i]+minv) / simtemp );</span></a>
<a name="146"><span class="lineNum">     146 </span>            :   // Initialize Z</a>
<a name="147"><span class="lineNum">     147 </span><span class="lineCov">          7 :   std::vector&lt;double&gt; Z( nreplicas, 1.0 ), oldZ( nreplicas );</span></a>
<a name="148"><span class="lineNum">     148 </span>            :   // Now the iterative loop to calculate the WHAM weights</a>
<a name="149"><span class="lineNum">     149 </span><span class="lineCov">       2674 :   for(unsigned iter=0; iter&lt;maxiter; ++iter) {</span></a>
<a name="150"><span class="lineNum">     150 </span>            :     // Store Z</a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">      18718 :     for(unsigned j=0; j&lt;Z.size(); ++j) oldZ[j]=Z[j];</span></a>
<a name="152"><span class="lineNum">     152 </span>            :     // Recompute weights</a>
<a name="153"><span class="lineNum">     153 </span>            :     double norm=0;</a>
<a name="154"><span class="lineNum">     154 </span><span class="lineCov">     941248 :     for(unsigned j=0; j&lt;final_weights.size(); ++j) {</span></a>
<a name="155"><span class="lineNum">     155 </span>            :       double ew=0;</a>
<a name="156"><span class="lineNum">     156 </span><span class="lineCov">    6570018 :       for(unsigned k=0; k&lt;Z.size(); ++k) ew += expv[j*Z.size()+k]  / Z[k];</span></a>
<a name="157"><span class="lineNum">     157 </span><span class="lineCov">     938574 :       final_weights[j] = 1.0 / ew; norm += final_weights[j];</span></a>
<a name="158"><span class="lineNum">     158 </span>            :     }</a>
<a name="159"><span class="lineNum">     159 </span>            :     // Normalize weights</a>
<a name="160"><span class="lineNum">     160 </span><span class="lineCov">     941248 :     for(unsigned j=0; j&lt;final_weights.size(); ++j) final_weights[j] /= norm;</span></a>
<a name="161"><span class="lineNum">     161 </span>            :     // Recompute Z</a>
<a name="162"><span class="lineNum">     162 </span><span class="lineCov">      18718 :     for(unsigned j=0; j&lt;Z.size(); ++j) Z[j] = 0.0;</span></a>
<a name="163"><span class="lineNum">     163 </span><span class="lineCov">     941248 :     for(unsigned j=0; j&lt;final_weights.size(); ++j) {</span></a>
<a name="164"><span class="lineNum">     164 </span><span class="lineCov">    6570018 :       for(unsigned k=0; k&lt;Z.size(); ++k) Z[k] += final_weights[j]*expv[j*Z.size()+k];</span></a>
<a name="165"><span class="lineNum">     165 </span>            :     }</a>
<a name="166"><span class="lineNum">     166 </span>            :     // Normalize Z and compute change in Z</a>
<a name="167"><span class="lineNum">     167 </span><span class="lineCov">      18718 :     double change=0; norm=0; for(unsigned k=0; k&lt;Z.size(); ++k) norm+=Z[k];</span></a>
<a name="168"><span class="lineNum">     168 </span><span class="lineCov">      18718 :     for(unsigned k=0; k&lt;Z.size(); ++k) {</span></a>
<a name="169"><span class="lineNum">     169 </span><span class="lineCov">      16044 :       Z[k] /= norm; double d = std::log( Z[k] / oldZ[k] ); change += d*d;</span></a>
<a name="170"><span class="lineNum">     170 </span>            :     }</a>
<a name="171"><span class="lineNum">     171 </span><span class="lineCov">       2681 :     if( change&lt;thresh ) { weightsCalculated=true; return; }</span></a>
<a name="172"><span class="lineNum">     172 </span>            :   }</a>
<a name="173"><span class="lineNum">     173 </span><span class="lineNoCov">          0 :   error(&quot;Too many iterations in WHAM&quot; );</span></a>
<a name="174"><span class="lineNum">     174 </span>            : }</a>
<a name="175"><span class="lineNum">     175 </span>            : </a>
<a name="176"><span class="lineNum">     176 </span>            : }</a>
<a name="177"><span class="lineNum">     177 </span>            : }</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
