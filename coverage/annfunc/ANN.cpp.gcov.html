<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - plumed test coverage - annfunc/ANN.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">annfunc</a> - ANN.cpp<span style="font-size: 80%;"> (source / <a href="ANN.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">plumed test coverage</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">134</td>
            <td class="headerCovTableEntry">138</td>
            <td class="headerCovTableEntryHi">97.1 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2024-10-18 14:29:08</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntry">9</td>
            <td class="headerCovTableEntryMed">88.9 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</a>
<a name="2"><span class="lineNum">       2 </span>            : MIT License</a>
<a name="3"><span class="lineNum">       3 </span>            : </a>
<a name="4"><span class="lineNum">       4 </span>            : Copyright (c) 2019 Wei Chen and Andrew Ferguson</a>
<a name="5"><span class="lineNum">       5 </span>            : </a>
<a name="6"><span class="lineNum">       6 </span>            : Permission is hereby granted, free of charge, to any person obtaining a copy</a>
<a name="7"><span class="lineNum">       7 </span>            : of this software and associated documentation files (the &quot;Software&quot;), to deal</a>
<a name="8"><span class="lineNum">       8 </span>            : in the Software without restriction, including without limitation the rights</a>
<a name="9"><span class="lineNum">       9 </span>            : to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</a>
<a name="10"><span class="lineNum">      10 </span>            : copies of the Software, and to permit persons to whom the Software is</a>
<a name="11"><span class="lineNum">      11 </span>            : furnished to do so, subject to the following conditions:</a>
<a name="12"><span class="lineNum">      12 </span>            : </a>
<a name="13"><span class="lineNum">      13 </span>            : The above copyright notice and this permission notice shall be included in all</a>
<a name="14"><span class="lineNum">      14 </span>            : copies or substantial portions of the Software.</a>
<a name="15"><span class="lineNum">      15 </span>            : </a>
<a name="16"><span class="lineNum">      16 </span>            : THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</a>
<a name="17"><span class="lineNum">      17 </span>            : IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</a>
<a name="18"><span class="lineNum">      18 </span>            : FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</a>
<a name="19"><span class="lineNum">      19 </span>            : AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</a>
<a name="20"><span class="lineNum">      20 </span>            : LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</a>
<a name="21"><span class="lineNum">      21 </span>            : OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</a>
<a name="22"><span class="lineNum">      22 </span>            : SOFTWARE.</a>
<a name="23"><span class="lineNum">      23 </span>            : +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ */</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &quot;function/Function.h&quot;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &quot;function/ActionRegister.h&quot;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &quot;cassert&quot;</a>
<a name="27"><span class="lineNum">      27 </span>            : </a>
<a name="28"><span class="lineNum">      28 </span>            : #include &lt;string&gt;</a>
<a name="29"><span class="lineNum">      29 </span>            : #include &lt;cmath&gt;</a>
<a name="30"><span class="lineNum">      30 </span>            : #include &lt;iostream&gt;</a>
<a name="31"><span class="lineNum">      31 </span>            : // #include &lt;stdio.h&gt;</a>
<a name="32"><span class="lineNum">      32 </span>            : </a>
<a name="33"><span class="lineNum">      33 </span>            : using namespace std;</a>
<a name="34"><span class="lineNum">      34 </span>            : </a>
<a name="35"><span class="lineNum">      35 </span>            : // #define DEBUG</a>
<a name="36"><span class="lineNum">      36 </span>            : // #define DEBUG_2</a>
<a name="37"><span class="lineNum">      37 </span>            : // #define DEBUG_3</a>
<a name="38"><span class="lineNum">      38 </span>            : </a>
<a name="39"><span class="lineNum">      39 </span>            : namespace PLMD {</a>
<a name="40"><span class="lineNum">      40 </span>            : namespace function {</a>
<a name="41"><span class="lineNum">      41 </span>            : namespace annfunc {</a>
<a name="42"><span class="lineNum">      42 </span>            : </a>
<a name="43"><span class="lineNum">      43 </span>            : //+PLUMEDOC ANNMOD_Function ANN</a>
<a name="44"><span class="lineNum">      44 </span>            : /*</a>
<a name="45"><span class="lineNum">      45 </span>            : Calculates the ANN-function.</a>
<a name="46"><span class="lineNum">      46 </span>            : </a>
<a name="47"><span class="lineNum">      47 </span>            : This module implements ANN class, which is a subclass of Function class.</a>
<a name="48"><span class="lineNum">      48 </span>            : ANN class takes multi-dimensional arrays as inputs for a fully-connected feedforward neural network</a>
<a name="49"><span class="lineNum">      49 </span>            : with specified neural network weights and generates corresponding outputs.</a>
<a name="50"><span class="lineNum">      50 </span>            : The ANN outputs can be used as collective variables, inputs for other collective variables,</a>
<a name="51"><span class="lineNum">      51 </span>            : or inputs for data analysis tools.</a>
<a name="52"><span class="lineNum">      52 </span>            : </a>
<a name="53"><span class="lineNum">      53 </span>            : \par Examples</a>
<a name="54"><span class="lineNum">      54 </span>            : </a>
<a name="55"><span class="lineNum">      55 </span>            : Assume we have an ANN with numbers of nodes being [2, 3, 1], and weights connecting layer 0 and 1 are</a>
<a name="56"><span class="lineNum">      56 </span>            : </a>
<a name="57"><span class="lineNum">      57 </span>            : [[1,2], [3,4], [5,6]]</a>
<a name="58"><span class="lineNum">      58 </span>            : </a>
<a name="59"><span class="lineNum">      59 </span>            : weights connecting layer 1 and 2 are</a>
<a name="60"><span class="lineNum">      60 </span>            : </a>
<a name="61"><span class="lineNum">      61 </span>            : [[7,8,9]]</a>
<a name="62"><span class="lineNum">      62 </span>            : </a>
<a name="63"><span class="lineNum">      63 </span>            : Bias for layer 1 and 2 are [10, 11, 12] and [13], respectively.</a>
<a name="64"><span class="lineNum">      64 </span>            : </a>
<a name="65"><span class="lineNum">      65 </span>            : All activation functions are Tanh.</a>
<a name="66"><span class="lineNum">      66 </span>            : </a>
<a name="67"><span class="lineNum">      67 </span>            : Then if input variables are l_0_out_0, l_0_out_1, the corresponding ANN function object can be defined using</a>
<a name="68"><span class="lineNum">      68 </span>            : following plumed script:</a>
<a name="69"><span class="lineNum">      69 </span>            : </a>
<a name="70"><span class="lineNum">      70 </span>            : \plumedfile</a>
<a name="71"><span class="lineNum">      71 </span>            : ANN ...</a>
<a name="72"><span class="lineNum">      72 </span>            : LABEL=ann</a>
<a name="73"><span class="lineNum">      73 </span>            : ARG=l_0_out_0,l_0_out_1</a>
<a name="74"><span class="lineNum">      74 </span>            : NUM_LAYERS=3</a>
<a name="75"><span class="lineNum">      75 </span>            : NUM_NODES=2,3,1</a>
<a name="76"><span class="lineNum">      76 </span>            : ACTIVATIONS=Tanh,Tanh</a>
<a name="77"><span class="lineNum">      77 </span>            : WEIGHTS0=1,2,3,4,5,6</a>
<a name="78"><span class="lineNum">      78 </span>            : WEIGHTS1=7,8,9</a>
<a name="79"><span class="lineNum">      79 </span>            : BIASES0=10,11,12</a>
<a name="80"><span class="lineNum">      80 </span>            : BIASES1=13</a>
<a name="81"><span class="lineNum">      81 </span>            : ... ANN</a>
<a name="82"><span class="lineNum">      82 </span>            : \endplumedfile</a>
<a name="83"><span class="lineNum">      83 </span>            : </a>
<a name="84"><span class="lineNum">      84 </span>            : To access its components, we use &quot;ann.node-0&quot;, &quot;ann.node-1&quot;, ..., which represents the components of neural network outputs.</a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            : </a>
<a name="87"><span class="lineNum">      87 </span>            : */</a>
<a name="88"><span class="lineNum">      88 </span>            : //+ENDPLUMEDOC</a>
<a name="89"><span class="lineNum">      89 </span>            : </a>
<a name="90"><span class="lineNum">      90 </span>            : class ANN : public Function</a>
<a name="91"><span class="lineNum">      91 </span>            : {</a>
<a name="92"><span class="lineNum">      92 </span>            : private:</a>
<a name="93"><span class="lineNum">      93 </span>            :   int num_layers;</a>
<a name="94"><span class="lineNum">      94 </span>            :   vector&lt;int&gt; num_nodes;</a>
<a name="95"><span class="lineNum">      95 </span>            :   vector&lt;string&gt; activations;   // activation functions</a>
<a name="96"><span class="lineNum">      96 </span>            :   vector&lt;vector&lt;double&gt; &gt; weights;  // flattened weight arrays</a>
<a name="97"><span class="lineNum">      97 </span>            :   vector&lt;vector&lt;double&gt; &gt; biases;</a>
<a name="98"><span class="lineNum">      98 </span>            :   vector&lt;vector&lt;double&gt; &gt; output_of_each_layer;</a>
<a name="99"><span class="lineNum">      99 </span>            :   vector&lt;vector&lt;double&gt; &gt; input_of_each_layer;</a>
<a name="100"><span class="lineNum">     100 </span>            :   vector&lt;double** &gt; coeff;  // weight matrix arrays, reshaped from &quot;weights&quot;</a>
<a name="101"><span class="lineNum">     101 </span>            : </a>
<a name="102"><span class="lineNum">     102 </span>            : public:</a>
<a name="103"><span class="lineNum">     103 </span>            :   static void registerKeywords( Keywords&amp; keys );</a>
<a name="104"><span class="lineNum">     104 </span>            :   explicit ANN(const ActionOptions&amp;);</a>
<a name="105"><span class="lineNum">     105 </span>            :   virtual void calculate();</a>
<a name="106"><span class="lineNum">     106 </span>            :   void calculate_output_of_each_layer(const vector&lt;double&gt;&amp; input);</a>
<a name="107"><span class="lineNum">     107 </span>            :   void back_prop(vector&lt;vector&lt;double&gt; &gt;&amp; derivatives_of_each_layer, int index_of_output_component);</a>
<a name="108"><span class="lineNum">     108 </span>            : };</a>
<a name="109"><span class="lineNum">     109 </span>            : </a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">      12619 : PLUMED_REGISTER_ACTION(ANN,&quot;ANN&quot;)</span></a>
<a name="111"><span class="lineNum">     111 </span>            : </a>
<a name="112"><span class="lineNum">     112 </span><span class="lineCov">          7 : void ANN::registerKeywords( Keywords&amp; keys ) {</span></a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">          7 :   Function::registerKeywords(keys);</span></a>
<a name="114"><span class="lineNum">     114 </span><span class="lineCov">         14 :   keys.use(&quot;ARG&quot;); keys.use(&quot;PERIODIC&quot;);</span></a>
<a name="115"><span class="lineNum">     115 </span><span class="lineCov">         14 :   keys.add(&quot;compulsory&quot;, &quot;NUM_LAYERS&quot;, &quot;number of layers of the neural network&quot;);</span></a>
<a name="116"><span class="lineNum">     116 </span><span class="lineCov">         14 :   keys.add(&quot;compulsory&quot;, &quot;NUM_NODES&quot;, &quot;numbers of nodes in each layer of the neural network&quot;);</span></a>
<a name="117"><span class="lineNum">     117 </span><span class="lineCov">         14 :   keys.add(&quot;compulsory&quot;, &quot;ACTIVATIONS&quot;, &quot;activation functions for the neural network&quot;);</span></a>
<a name="118"><span class="lineNum">     118 </span><span class="lineCov">         14 :   keys.add(&quot;numbered&quot;, &quot;WEIGHTS&quot;, &quot;flattened weight arrays connecting adjacent layers, &quot;</span></a>
<a name="119"><span class="lineNum">     119 </span>            :            &quot;WEIGHTS0 represents flattened weight array connecting layer 0 and layer 1, &quot;</a>
<a name="120"><span class="lineNum">     120 </span>            :            &quot;WEIGHTS1 represents flattened weight array connecting layer 1 and layer 2, ...&quot;);</a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">         14 :   keys.add(&quot;numbered&quot;, &quot;BIASES&quot;, &quot;bias array for each layer of the neural network, &quot;</span></a>
<a name="122"><span class="lineNum">     122 </span>            :            &quot;BIASES0 represents bias array for layer 1, BIASES1 represents bias array for layer 2, ...&quot;);</a>
<a name="123"><span class="lineNum">     123 </span>            :   // since v2.2 plumed requires all components be registered</a>
<a name="124"><span class="lineNum">     124 </span><span class="lineCov">         14 :   keys.addOutputComponent(&quot;node&quot;, &quot;default&quot;, &quot;components of ANN outputs&quot;);</span></a>
<a name="125"><span class="lineNum">     125 </span><span class="lineCov">          7 : }</span></a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">          5 : ANN::ANN(const ActionOptions&amp;ao):</span></a>
<a name="128"><span class="lineNum">     128 </span>            :   Action(ao),</a>
<a name="129"><span class="lineNum">     129 </span><span class="lineCov">          5 :   Function(ao)</span></a>
<a name="130"><span class="lineNum">     130 </span>            : {</a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">          5 :   parse(&quot;NUM_LAYERS&quot;, num_layers);</span></a>
<a name="132"><span class="lineNum">     132 </span><span class="lineCov">          5 :   num_nodes = vector&lt;int&gt;(num_layers);</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineCov">         10 :   activations = vector&lt;string&gt;(num_layers - 1);</span></a>
<a name="134"><span class="lineNum">     134 </span><span class="lineCov">         10 :   output_of_each_layer = vector&lt;vector&lt;double&gt; &gt;(num_layers);</span></a>
<a name="135"><span class="lineNum">     135 </span><span class="lineCov">         10 :   input_of_each_layer = vector&lt;vector&lt;double&gt; &gt;(num_layers);</span></a>
<a name="136"><span class="lineNum">     136 </span><span class="lineCov">          5 :   coeff = vector&lt;double** &gt;(num_layers - 1);</span></a>
<a name="137"><span class="lineNum">     137 </span><span class="lineCov">          5 :   parseVector(&quot;NUM_NODES&quot;, num_nodes);</span></a>
<a name="138"><span class="lineNum">     138 </span><span class="lineCov">          5 :   parseVector(&quot;ACTIVATIONS&quot;, activations);</span></a>
<a name="139"><span class="lineNum">     139 </span><span class="lineCov">          5 :   log.printf(&quot;\nactivations = &quot;);</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineCov">         15 :   for (auto ss: activations) {</span></a>
<a name="141"><span class="lineNum">     141 </span><span class="lineCov">         10 :     log.printf(&quot;%s, &quot;, ss.c_str());</span></a>
<a name="142"><span class="lineNum">     142 </span>            :   }</a>
<a name="143"><span class="lineNum">     143 </span><span class="lineCov">          5 :   log.printf(&quot;\nnum_nodes = &quot;);</span></a>
<a name="144"><span class="lineNum">     144 </span><span class="lineCov">         20 :   for (auto ss: num_nodes) {</span></a>
<a name="145"><span class="lineNum">     145 </span><span class="lineCov">         15 :     log.printf(&quot;%d, &quot;, ss);</span></a>
<a name="146"><span class="lineNum">     146 </span>            :   }</a>
<a name="147"><span class="lineNum">     147 </span>            :   vector&lt;double&gt; temp_single_coeff, temp_single_bias;</a>
<a name="148"><span class="lineNum">     148 </span><span class="lineCov">         10 :   for (int ii = 0; ; ii ++) {</span></a>
<a name="149"><span class="lineNum">     149 </span>            :     // parse coeff</a>
<a name="150"><span class="lineNum">     150 </span><span class="lineCov">         30 :     if( !parseNumberedVector(&quot;WEIGHTS&quot;, ii, temp_single_coeff) ) {</span></a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">          5 :       temp_single_coeff=weights[ii-1];</span></a>
<a name="152"><span class="lineNum">     152 </span>            :       break;</a>
<a name="153"><span class="lineNum">     153 </span>            :     }</a>
<a name="154"><span class="lineNum">     154 </span><span class="lineCov">         10 :     weights.push_back(temp_single_coeff);</span></a>
<a name="155"><span class="lineNum">     155 </span><span class="lineCov">         10 :     log.printf(&quot;size of temp_single_coeff = %lu\n&quot;, temp_single_coeff.size());</span></a>
<a name="156"><span class="lineNum">     156 </span><span class="lineCov">         10 :     log.printf(&quot;size of weights = %lu\n&quot;, weights.size());</span></a>
<a name="157"><span class="lineNum">     157 </span>            :     // parse bias</a>
<a name="158"><span class="lineNum">     158 </span><span class="lineCov">         20 :     if( !parseNumberedVector(&quot;BIASES&quot;, ii, temp_single_bias) ) {</span></a>
<a name="159"><span class="lineNum">     159 </span><span class="lineNoCov">          0 :       temp_single_bias=biases[ii-1];</span></a>
<a name="160"><span class="lineNum">     160 </span>            :     }</a>
<a name="161"><span class="lineNum">     161 </span><span class="lineCov">         10 :     biases.push_back(temp_single_bias);</span></a>
<a name="162"><span class="lineNum">     162 </span><span class="lineCov">         10 :     log.printf(&quot;size of temp_single_bias = %lu\n&quot;, temp_single_bias.size());</span></a>
<a name="163"><span class="lineNum">     163 </span><span class="lineCov">         10 :     log.printf(&quot;size of biases = %lu\n&quot;, biases.size());</span></a>
<a name="164"><span class="lineNum">     164 </span>            :   }</a>
<a name="165"><span class="lineNum">     165 </span>            : </a>
<a name="166"><span class="lineNum">     166 </span><span class="lineCov">          5 :   if(getNumberOfArguments() != num_nodes[0]) {</span></a>
<a name="167"><span class="lineNum">     167 </span><span class="lineNoCov">          0 :     error(&quot;Number of arguments is wrong&quot;);</span></a>
<a name="168"><span class="lineNum">     168 </span>            :   }</a>
<a name="169"><span class="lineNum">     169 </span>            : </a>
<a name="170"><span class="lineNum">     170 </span><span class="lineCov">          5 :   auto temp_coeff = weights;</span></a>
<a name="171"><span class="lineNum">     171 </span><span class="lineCov">         15 :   for (int ii = 0; ii &lt; num_layers - 1; ii ++) {</span></a>
<a name="172"><span class="lineNum">     172 </span>            :     int num_of_rows, num_of_cols; // num of rows/cols for the coeff matrix of this connection</a>
<a name="173"><span class="lineNum">     173 </span><span class="lineCov">         10 :     num_of_rows = num_nodes[ii + 1];</span></a>
<a name="174"><span class="lineNum">     174 </span><span class="lineCov">         10 :     num_of_cols = num_nodes[ii];</span></a>
<a name="175"><span class="lineNum">     175 </span>            :     assert (num_of_rows * num_of_cols == temp_coeff[ii].size()); // check whether the size matches</a>
<a name="176"><span class="lineNum">     176 </span>            :     // create a 2d array to hold coefficients</a>
<a name="177"><span class="lineNum">     177 </span><span class="lineCov">         10 :     coeff[ii] = new double*[num_of_rows];</span></a>
<a name="178"><span class="lineNum">     178 </span><span class="lineCov">         32 :     for (int kk = 0; kk &lt; num_of_rows; kk ++) {</span></a>
<a name="179"><span class="lineNum">     179 </span><span class="lineCov">         22 :       coeff[ii][kk] = new double[num_of_cols];</span></a>
<a name="180"><span class="lineNum">     180 </span>            :     }</a>
<a name="181"><span class="lineNum">     181 </span><span class="lineCov">         61 :     for (int jj = 0; jj &lt; temp_coeff[ii].size(); jj ++) {</span></a>
<a name="182"><span class="lineNum">     182 </span><span class="lineCov">         51 :       coeff[ii][jj / num_of_cols][jj % num_of_cols] = temp_coeff[ii][jj];</span></a>
<a name="183"><span class="lineNum">     183 </span>            :     }</a>
<a name="184"><span class="lineNum">     184 </span>            :   }</a>
<a name="185"><span class="lineNum">     185 </span>            :   // check coeff</a>
<a name="186"><span class="lineNum">     186 </span><span class="lineCov">         15 :   for (int ii = 0; ii &lt; num_layers - 1; ii ++) {</span></a>
<a name="187"><span class="lineNum">     187 </span><span class="lineCov">         10 :     log.printf(&quot;coeff %d = \n&quot;, ii);</span></a>
<a name="188"><span class="lineNum">     188 </span><span class="lineCov">         32 :     for (int jj = 0; jj &lt; num_nodes[ii + 1]; jj ++) {</span></a>
<a name="189"><span class="lineNum">     189 </span><span class="lineCov">         73 :       for (int kk = 0; kk &lt; num_nodes[ii]; kk ++) {</span></a>
<a name="190"><span class="lineNum">     190 </span><span class="lineCov">         51 :         log.printf(&quot;%f &quot;, coeff[ii][jj][kk]);</span></a>
<a name="191"><span class="lineNum">     191 </span>            :       }</a>
<a name="192"><span class="lineNum">     192 </span><span class="lineCov">         22 :       log.printf(&quot;\n&quot;);</span></a>
<a name="193"><span class="lineNum">     193 </span>            :     }</a>
<a name="194"><span class="lineNum">     194 </span>            :   }</a>
<a name="195"><span class="lineNum">     195 </span>            :   // check bias</a>
<a name="196"><span class="lineNum">     196 </span><span class="lineCov">         15 :   for (int ii = 0; ii &lt; num_layers - 1; ii ++) {</span></a>
<a name="197"><span class="lineNum">     197 </span><span class="lineCov">         10 :     log.printf(&quot;bias %d = \n&quot;, ii);</span></a>
<a name="198"><span class="lineNum">     198 </span><span class="lineCov">         32 :     for (int jj = 0; jj &lt; num_nodes[ii + 1]; jj ++) {</span></a>
<a name="199"><span class="lineNum">     199 </span><span class="lineCov">         22 :       log.printf(&quot;%f &quot;, biases[ii][jj]);</span></a>
<a name="200"><span class="lineNum">     200 </span>            :     }</a>
<a name="201"><span class="lineNum">     201 </span><span class="lineCov">         10 :     log.printf(&quot;\n&quot;);</span></a>
<a name="202"><span class="lineNum">     202 </span>            :   }</a>
<a name="203"><span class="lineNum">     203 </span><span class="lineCov">          5 :   log.printf(&quot;initialization ended\n&quot;);</span></a>
<a name="204"><span class="lineNum">     204 </span>            :   // create components</a>
<a name="205"><span class="lineNum">     205 </span><span class="lineCov">         12 :   for (int ii = 0; ii &lt; num_nodes[num_layers - 1]; ii ++) {</span></a>
<a name="206"><span class="lineNum">     206 </span><span class="lineCov">          7 :     string name_of_this_component = &quot;node-&quot; + to_string(ii);</span></a>
<a name="207"><span class="lineNum">     207 </span><span class="lineCov">          7 :     addComponentWithDerivatives(name_of_this_component);</span></a>
<a name="208"><span class="lineNum">     208 </span><span class="lineCov">          7 :     componentIsNotPeriodic(name_of_this_component);</span></a>
<a name="209"><span class="lineNum">     209 </span>            :   }</a>
<a name="210"><span class="lineNum">     210 </span><span class="lineCov">          5 :   checkRead();</span></a>
<a name="211"><span class="lineNum">     211 </span><span class="lineCov">         10 : }</span></a>
<a name="212"><span class="lineNum">     212 </span>            : </a>
<a name="213"><span class="lineNum">     213 </span><span class="lineCov">       1638 : void ANN::calculate_output_of_each_layer(const vector&lt;double&gt;&amp; input) {</span></a>
<a name="214"><span class="lineNum">     214 </span>            :   // first layer</a>
<a name="215"><span class="lineNum">     215 </span><span class="lineCov">       1638 :   output_of_each_layer[0] = input;</span></a>
<a name="216"><span class="lineNum">     216 </span>            :   // following layers</a>
<a name="217"><span class="lineNum">     217 </span><span class="lineCov">       4914 :   for(int ii = 1; ii &lt; num_nodes.size(); ii ++) {</span></a>
<a name="218"><span class="lineNum">     218 </span><span class="lineCov">       3276 :     output_of_each_layer[ii].resize(num_nodes[ii]);</span></a>
<a name="219"><span class="lineNum">     219 </span><span class="lineCov">       3276 :     input_of_each_layer[ii].resize(num_nodes[ii]);</span></a>
<a name="220"><span class="lineNum">     220 </span>            :     // first calculate input</a>
<a name="221"><span class="lineNum">     221 </span><span class="lineCov">      10374 :     for (int jj = 0; jj &lt; num_nodes[ii]; jj ++) {</span></a>
<a name="222"><span class="lineNum">     222 </span><span class="lineCov">       7098 :       input_of_each_layer[ii][jj] = biases[ii - 1][jj];  // add bias term</span></a>
<a name="223"><span class="lineNum">     223 </span><span class="lineCov">      23478 :       for (int kk = 0; kk &lt; num_nodes[ii - 1]; kk ++) {</span></a>
<a name="224"><span class="lineNum">     224 </span><span class="lineCov">      16380 :         input_of_each_layer[ii][jj] += coeff[ii - 1][jj][kk] * output_of_each_layer[ii - 1][kk];</span></a>
<a name="225"><span class="lineNum">     225 </span>            :       }</a>
<a name="226"><span class="lineNum">     226 </span>            :     }</a>
<a name="227"><span class="lineNum">     227 </span>            :     // then get output</a>
<a name="228"><span class="lineNum">     228 </span><span class="lineCov">       3276 :     if (activations[ii - 1] == string(&quot;Linear&quot;)) {</span></a>
<a name="229"><span class="lineNum">     229 </span><span class="lineCov">       1092 :       for(int jj = 0; jj &lt; num_nodes[ii]; jj ++) {</span></a>
<a name="230"><span class="lineNum">     230 </span><span class="lineCov">        546 :         output_of_each_layer[ii][jj] = input_of_each_layer[ii][jj];</span></a>
<a name="231"><span class="lineNum">     231 </span>            :       }</a>
<a name="232"><span class="lineNum">     232 </span>            :     }</a>
<a name="233"><span class="lineNum">     233 </span><span class="lineCov">       2730 :     else if (activations[ii - 1] == string(&quot;Tanh&quot;)) {</span></a>
<a name="234"><span class="lineNum">     234 </span><span class="lineCov">       7644 :       for(int jj = 0; jj &lt; num_nodes[ii]; jj ++) {</span></a>
<a name="235"><span class="lineNum">     235 </span><span class="lineCov">       5460 :         output_of_each_layer[ii][jj] = tanh(input_of_each_layer[ii][jj]);</span></a>
<a name="236"><span class="lineNum">     236 </span>            :       }</a>
<a name="237"><span class="lineNum">     237 </span>            :     }</a>
<a name="238"><span class="lineNum">     238 </span><span class="lineCov">        546 :     else if (activations[ii - 1] == string(&quot;Circular&quot;)) {</span></a>
<a name="239"><span class="lineNum">     239 </span>            :       assert (num_nodes[ii] % 2 == 0);</a>
<a name="240"><span class="lineNum">     240 </span><span class="lineCov">       1092 :       for(int jj = 0; jj &lt; num_nodes[ii] / 2; jj ++) {</span></a>
<a name="241"><span class="lineNum">     241 </span><span class="lineCov">        546 :         double radius = sqrt(input_of_each_layer[ii][2 * jj] * input_of_each_layer[ii][2 * jj]</span></a>
<a name="242"><span class="lineNum">     242 </span><span class="lineCov">        546 :                              +input_of_each_layer[ii][2 * jj + 1] * input_of_each_layer[ii][2 * jj + 1]);</span></a>
<a name="243"><span class="lineNum">     243 </span><span class="lineCov">        546 :         output_of_each_layer[ii][2 * jj] = input_of_each_layer[ii][2 * jj] / radius;</span></a>
<a name="244"><span class="lineNum">     244 </span><span class="lineCov">        546 :         output_of_each_layer[ii][2 * jj + 1] = input_of_each_layer[ii][2 * jj + 1] / radius;</span></a>
<a name="245"><span class="lineNum">     245 </span>            : </a>
<a name="246"><span class="lineNum">     246 </span>            :       }</a>
<a name="247"><span class="lineNum">     247 </span>            :     }</a>
<a name="248"><span class="lineNum">     248 </span>            :     else {</a>
<a name="249"><span class="lineNum">     249 </span>            :       printf(&quot;layer type not found!\n\n&quot;);</a>
<a name="250"><span class="lineNum">     250 </span><span class="lineNoCov">          0 :       return;</span></a>
<a name="251"><span class="lineNum">     251 </span>            :     }</a>
<a name="252"><span class="lineNum">     252 </span>            :   }</a>
<a name="253"><span class="lineNum">     253 </span>            : #ifdef DEBUG_2</a>
<a name="254"><span class="lineNum">     254 </span>            :   // print out the result for debugging</a>
<a name="255"><span class="lineNum">     255 </span>            :   printf(&quot;output_of_each_layer = \n&quot;);</a>
<a name="256"><span class="lineNum">     256 </span>            :   // for (int ii = num_layers - 1; ii &lt; num_layers; ii ++) {</a>
<a name="257"><span class="lineNum">     257 </span>            :   for (int ii = 0; ii &lt; num_layers; ii ++) {</a>
<a name="258"><span class="lineNum">     258 </span>            :     printf(&quot;layer[%d]: &quot;, ii);</a>
<a name="259"><span class="lineNum">     259 </span>            :     if (ii != 0) {</a>
<a name="260"><span class="lineNum">     260 </span>            :       cout &lt;&lt; activations[ii - 1] &lt;&lt; &quot;\t&quot;;</a>
<a name="261"><span class="lineNum">     261 </span>            :     }</a>
<a name="262"><span class="lineNum">     262 </span>            :     else {</a>
<a name="263"><span class="lineNum">     263 </span>            :       cout &lt;&lt; &quot;input \t&quot; ;</a>
<a name="264"><span class="lineNum">     264 </span>            :     }</a>
<a name="265"><span class="lineNum">     265 </span>            :     for (int jj = 0; jj &lt; num_nodes[ii]; jj ++) {</a>
<a name="266"><span class="lineNum">     266 </span>            :       printf(&quot;%lf\t&quot;, output_of_each_layer[ii][jj]);</a>
<a name="267"><span class="lineNum">     267 </span>            :     }</a>
<a name="268"><span class="lineNum">     268 </span>            :     printf(&quot;\n&quot;);</a>
<a name="269"><span class="lineNum">     269 </span>            :   }</a>
<a name="270"><span class="lineNum">     270 </span>            :   printf(&quot;\n&quot;);</a>
<a name="271"><span class="lineNum">     271 </span>            : #endif</a>
<a name="272"><span class="lineNum">     272 </span>            :   return;</a>
<a name="273"><span class="lineNum">     273 </span>            : }</a>
<a name="274"><span class="lineNum">     274 </span>            : </a>
<a name="275"><span class="lineNum">     275 </span><span class="lineCov">       2184 : void ANN::back_prop(vector&lt;vector&lt;double&gt; &gt;&amp; derivatives_of_each_layer, int index_of_output_component) {</span></a>
<a name="276"><span class="lineNum">     276 </span><span class="lineCov">       2184 :   derivatives_of_each_layer = output_of_each_layer;  // the data structure and size should be the same, so I simply deep copy it</span></a>
<a name="277"><span class="lineNum">     277 </span>            :   // first calculate derivatives for bottleneck layer</a>
<a name="278"><span class="lineNum">     278 </span><span class="lineCov">       5460 :   for (int ii = 0; ii &lt; num_nodes[num_nodes.size() - 1]; ii ++ ) {</span></a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">       3276 :     if (ii == index_of_output_component) {</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">       2184 :       derivatives_of_each_layer[num_nodes.size() - 1][ii] = 1;</span></a>
<a name="281"><span class="lineNum">     281 </span>            :     }</a>
<a name="282"><span class="lineNum">     282 </span>            :     else {</a>
<a name="283"><span class="lineNum">     283 </span><span class="lineCov">       1092 :       derivatives_of_each_layer[num_nodes.size() - 1][ii] = 0;</span></a>
<a name="284"><span class="lineNum">     284 </span>            :     }</a>
<a name="285"><span class="lineNum">     285 </span>            :   }</a>
<a name="286"><span class="lineNum">     286 </span>            :   // the use back propagation to calculate derivatives for previous layers</a>
<a name="287"><span class="lineNum">     287 </span><span class="lineCov">       6552 :   for (int jj = num_nodes.size() - 2; jj &gt;= 0; jj --) {</span></a>
<a name="288"><span class="lineNum">     288 </span><span class="lineCov">       4368 :     if (activations[jj] == string(&quot;Circular&quot;)) {</span></a>
<a name="289"><span class="lineNum">     289 </span>            :       vector&lt;double&gt; temp_derivative_of_input_for_this_layer;</a>
<a name="290"><span class="lineNum">     290 </span><span class="lineCov">       1092 :       temp_derivative_of_input_for_this_layer.resize(num_nodes[jj + 1]);</span></a>
<a name="291"><span class="lineNum">     291 </span>            : #ifdef DEBUG</a>
<a name="292"><span class="lineNum">     292 </span>            :       assert (num_nodes[jj + 1] % 2 == 0);</a>
<a name="293"><span class="lineNum">     293 </span>            : #endif</a>
<a name="294"><span class="lineNum">     294 </span>            :       // first calculate the derivative of input from derivative of output of this circular layer</a>
<a name="295"><span class="lineNum">     295 </span><span class="lineCov">       2184 :       for(int ii = 0; ii &lt; num_nodes[jj + 1] / 2; ii ++) {</span></a>
<a name="296"><span class="lineNum">     296 </span>            :         // printf(&quot;size of input_of_each_layer[%d] = %d\n&quot;,jj,  input_of_each_layer[jj].size());</a>
<a name="297"><span class="lineNum">     297 </span><span class="lineCov">       1092 :         double x_p = input_of_each_layer[jj + 1][2 * ii];</span></a>
<a name="298"><span class="lineNum">     298 </span><span class="lineCov">       1092 :         double x_q = input_of_each_layer[jj + 1][2 * ii + 1];</span></a>
<a name="299"><span class="lineNum">     299 </span><span class="lineCov">       1092 :         double radius = sqrt(x_p * x_p + x_q * x_q);</span></a>
<a name="300"><span class="lineNum">     300 </span><span class="lineCov">       1092 :         temp_derivative_of_input_for_this_layer[2 * ii] = x_q / (radius * radius * radius)</span></a>
<a name="301"><span class="lineNum">     301 </span><span class="lineCov">       1092 :             * (x_q * derivatives_of_each_layer[jj + 1][2 * ii]</span></a>
<a name="302"><span class="lineNum">     302 </span><span class="lineCov">       1092 :                - x_p * derivatives_of_each_layer[jj + 1][2 * ii + 1]);</span></a>
<a name="303"><span class="lineNum">     303 </span><span class="lineCov">       1092 :         temp_derivative_of_input_for_this_layer[2 * ii + 1] = x_p / (radius * radius * radius)</span></a>
<a name="304"><span class="lineNum">     304 </span><span class="lineCov">       1092 :             * (x_p * derivatives_of_each_layer[jj + 1][2 * ii + 1]</span></a>
<a name="305"><span class="lineNum">     305 </span><span class="lineCov">       1092 :                - x_q * derivatives_of_each_layer[jj + 1][2 * ii]);</span></a>
<a name="306"><span class="lineNum">     306 </span>            :       }</a>
<a name="307"><span class="lineNum">     307 </span>            : #ifdef DEBUG</a>
<a name="308"><span class="lineNum">     308 </span>            :       for (int mm = 0; mm &lt; num_nodes[jj + 1]; mm ++) {</a>
<a name="309"><span class="lineNum">     309 </span>            :         printf(&quot;temp_derivative_of_input_for_this_layer[%d] = %lf\n&quot;, mm, temp_derivative_of_input_for_this_layer[mm]);</a>
<a name="310"><span class="lineNum">     310 </span>            :         printf(&quot;derivatives_of_each_layer[%d + 1][%d] = %lf\n&quot;, jj, mm, derivatives_of_each_layer[jj + 1][mm]);</a>
<a name="311"><span class="lineNum">     311 </span>            :       }</a>
<a name="312"><span class="lineNum">     312 </span>            : #endif</a>
<a name="313"><span class="lineNum">     313 </span>            :       // the calculate the derivative of output of layer jj, from derivative of input of layer (jj + 1)</a>
<a name="314"><span class="lineNum">     314 </span><span class="lineCov">       4368 :       for (int mm = 0; mm &lt; num_nodes[jj]; mm ++) {</span></a>
<a name="315"><span class="lineNum">     315 </span><span class="lineCov">       3276 :         derivatives_of_each_layer[jj][mm] = 0;</span></a>
<a name="316"><span class="lineNum">     316 </span><span class="lineCov">       9828 :         for (int kk = 0; kk &lt; num_nodes[jj + 1]; kk ++) {</span></a>
<a name="317"><span class="lineNum">     317 </span><span class="lineCov">       6552 :           derivatives_of_each_layer[jj][mm] += coeff[jj][kk][mm] \</span></a>
<a name="318"><span class="lineNum">     318 </span><span class="lineCov">       6552 :                                                * temp_derivative_of_input_for_this_layer[kk];</span></a>
<a name="319"><span class="lineNum">     319 </span>            : #ifdef DEBUG</a>
<a name="320"><span class="lineNum">     320 </span>            :           printf(&quot;derivatives_of_each_layer[%d][%d] = %lf\n&quot;, jj, mm, derivatives_of_each_layer[jj][mm]);</a>
<a name="321"><span class="lineNum">     321 </span>            :           printf(&quot;coeff[%d][%d][%d] = %lf\n&quot;, jj, kk, mm, coeff[jj][kk][mm]);</a>
<a name="322"><span class="lineNum">     322 </span>            : #endif</a>
<a name="323"><span class="lineNum">     323 </span>            :         }</a>
<a name="324"><span class="lineNum">     324 </span>            :       }</a>
<a name="325"><span class="lineNum">     325 </span>            :       // TODO: should be fine, pass all tests, although there seems to be some problems here previously</a>
<a name="326"><span class="lineNum">     326 </span>            :     }</a>
<a name="327"><span class="lineNum">     327 </span>            :     else {</a>
<a name="328"><span class="lineNum">     328 </span><span class="lineCov">      10920 :       for (int mm = 0; mm &lt; num_nodes[jj]; mm ++) {</span></a>
<a name="329"><span class="lineNum">     329 </span><span class="lineCov">       7644 :         derivatives_of_each_layer[jj][mm] = 0;</span></a>
<a name="330"><span class="lineNum">     330 </span><span class="lineCov">      24024 :         for (int kk = 0; kk &lt; num_nodes[jj + 1]; kk ++) {</span></a>
<a name="331"><span class="lineNum">     331 </span><span class="lineCov">      16380 :           if (activations[jj] == string(&quot;Tanh&quot;)) {</span></a>
<a name="332"><span class="lineNum">     332 </span>            :             // printf(&quot;tanh\n&quot;);</a>
<a name="333"><span class="lineNum">     333 </span><span class="lineCov">      14742 :             derivatives_of_each_layer[jj][mm] += derivatives_of_each_layer[jj + 1][kk] \</span></a>
<a name="334"><span class="lineNum">     334 </span><span class="lineCov">      14742 :                                                  * coeff[jj][kk][mm] \</span></a>
<a name="335"><span class="lineNum">     335 </span><span class="lineCov">      14742 :                                                  * (1 - output_of_each_layer[jj + 1][kk] * output_of_each_layer[jj + 1][kk]);</span></a>
<a name="336"><span class="lineNum">     336 </span>            :           }</a>
<a name="337"><span class="lineNum">     337 </span><span class="lineCov">       1638 :           else if (activations[jj] == string(&quot;Linear&quot;)) {</span></a>
<a name="338"><span class="lineNum">     338 </span>            :             // printf(&quot;linear\n&quot;);</a>
<a name="339"><span class="lineNum">     339 </span><span class="lineCov">       1638 :             derivatives_of_each_layer[jj][mm] += derivatives_of_each_layer[jj + 1][kk] \</span></a>
<a name="340"><span class="lineNum">     340 </span><span class="lineCov">       1638 :                                                  * coeff[jj][kk][mm] \</span></a>
<a name="341"><span class="lineNum">     341 </span><span class="lineCov">       1638 :                                                  * 1;</span></a>
<a name="342"><span class="lineNum">     342 </span>            :           }</a>
<a name="343"><span class="lineNum">     343 </span>            :           else {</a>
<a name="344"><span class="lineNum">     344 </span>            :             printf(&quot;layer type not found!\n\n&quot;);</a>
<a name="345"><span class="lineNum">     345 </span><span class="lineNoCov">          0 :             return;</span></a>
<a name="346"><span class="lineNum">     346 </span>            :           }</a>
<a name="347"><span class="lineNum">     347 </span>            :         }</a>
<a name="348"><span class="lineNum">     348 </span>            :       }</a>
<a name="349"><span class="lineNum">     349 </span>            :     }</a>
<a name="350"><span class="lineNum">     350 </span>            :   }</a>
<a name="351"><span class="lineNum">     351 </span>            : #ifdef DEBUG</a>
<a name="352"><span class="lineNum">     352 </span>            :   // print out the result for debugging</a>
<a name="353"><span class="lineNum">     353 </span>            :   printf(&quot;derivatives_of_each_layer = \n&quot;);</a>
<a name="354"><span class="lineNum">     354 </span>            :   for (int ii = 0; ii &lt; num_layers; ii ++) {</a>
<a name="355"><span class="lineNum">     355 </span>            :     printf(&quot;layer[%d]: &quot;, ii);</a>
<a name="356"><span class="lineNum">     356 </span>            :     for (int jj = 0; jj &lt; num_nodes[ii]; jj ++) {</a>
<a name="357"><span class="lineNum">     357 </span>            :       printf(&quot;%lf\t&quot;, derivatives_of_each_layer[ii][jj]);</a>
<a name="358"><span class="lineNum">     358 </span>            :     }</a>
<a name="359"><span class="lineNum">     359 </span>            :     printf(&quot;\n&quot;);</a>
<a name="360"><span class="lineNum">     360 </span>            :   }</a>
<a name="361"><span class="lineNum">     361 </span>            :   printf(&quot;\n&quot;);</a>
<a name="362"><span class="lineNum">     362 </span>            : #endif</a>
<a name="363"><span class="lineNum">     363 </span>            :   return;</a>
<a name="364"><span class="lineNum">     364 </span>            : }</a>
<a name="365"><span class="lineNum">     365 </span>            : </a>
<a name="366"><span class="lineNum">     366 </span><span class="lineCov">       1638 : void ANN::calculate() {</span></a>
<a name="367"><span class="lineNum">     367 </span>            : </a>
<a name="368"><span class="lineNum">     368 </span><span class="lineCov">       1638 :   vector&lt;double&gt; input_layer_data(num_nodes[0]);</span></a>
<a name="369"><span class="lineNum">     369 </span><span class="lineCov">       4914 :   for (int ii = 0; ii &lt; num_nodes[0]; ii ++) {</span></a>
<a name="370"><span class="lineNum">     370 </span><span class="lineCov">       3276 :     input_layer_data[ii] = getArgument(ii);</span></a>
<a name="371"><span class="lineNum">     371 </span>            :   }</a>
<a name="372"><span class="lineNum">     372 </span>            : </a>
<a name="373"><span class="lineNum">     373 </span><span class="lineCov">       1638 :   calculate_output_of_each_layer(input_layer_data);</span></a>
<a name="374"><span class="lineNum">     374 </span>            :   vector&lt;vector&lt;double&gt; &gt; derivatives_of_each_layer;</a>
<a name="375"><span class="lineNum">     375 </span>            : </a>
<a name="376"><span class="lineNum">     376 </span><span class="lineCov">       3822 :   for (int ii = 0; ii &lt; num_nodes[num_layers - 1]; ii ++) {</span></a>
<a name="377"><span class="lineNum">     377 </span><span class="lineCov">       2184 :     back_prop(derivatives_of_each_layer, ii);</span></a>
<a name="378"><span class="lineNum">     378 </span><span class="lineCov">       2184 :     string name_of_this_component = &quot;node-&quot; + to_string(ii);</span></a>
<a name="379"><span class="lineNum">     379 </span><span class="lineCov">       2184 :     Value* value_new=getPntrToComponent(name_of_this_component);</span></a>
<a name="380"><span class="lineNum">     380 </span><span class="lineCov">       2184 :     value_new -&gt; set(output_of_each_layer[num_layers - 1][ii]);</span></a>
<a name="381"><span class="lineNum">     381 </span><span class="lineCov">       6552 :     for (int jj = 0; jj &lt; num_nodes[0]; jj ++) {</span></a>
<a name="382"><span class="lineNum">     382 </span><span class="lineCov">       4368 :       value_new -&gt; setDerivative(jj, derivatives_of_each_layer[0][jj]);  // TODO: setDerivative or addDerivative?</span></a>
<a name="383"><span class="lineNum">     383 </span>            :     }</a>
<a name="384"><span class="lineNum">     384 </span>            : #ifdef DEBUG_3</a>
<a name="385"><span class="lineNum">     385 </span>            :     printf(&quot;derivatives = &quot;);</a>
<a name="386"><span class="lineNum">     386 </span>            :     for (int jj = 0; jj &lt; num_nodes[0]; jj ++) {</a>
<a name="387"><span class="lineNum">     387 </span>            :       printf(&quot;%f &quot;, value_new -&gt; getDerivative(jj));</a>
<a name="388"><span class="lineNum">     388 </span>            :     }</a>
<a name="389"><span class="lineNum">     389 </span>            :     printf(&quot;\n&quot;);</a>
<a name="390"><span class="lineNum">     390 </span>            : #endif</a>
<a name="391"><span class="lineNum">     391 </span>            :   }</a>
<a name="392"><span class="lineNum">     392 </span>            : </a>
<a name="393"><span class="lineNum">     393 </span><span class="lineCov">       3276 : }</span></a>
<a name="394"><span class="lineNum">     394 </span>            : </a>
<a name="395"><span class="lineNum">     395 </span>            : }</a>
<a name="396"><span class="lineNum">     396 </span>            : }</a>
<a name="397"><span class="lineNum">     397 </span>            : }</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
